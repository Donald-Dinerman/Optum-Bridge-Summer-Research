-
title: "Clustering: Hierarchical Clustering"
output:
  pdf_document: default
  html_document: default
-

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hierarchical Clustering

## Prep NBA player dataset

Created dataset of NBA player statistics per 100 possessions using [`ballr`](https://cran.r-project.org/web/packages/ballr/vignettes/use-ballr.html)

```{r load-data, warning = FALSE, message = FALSE}
library(tidyverse)

nba_pos_stats <- read_csv("http://www.stat.cmu.edu/cmsac/sure/2022/materials/data/sports/clustering/nba_2022_player_per_pos_stats.csv")

# Find rows for players indicating a full season worth of stats
tot_players <- nba_pos_stats %>% filter(tm == "TOT")

# Stack this dataset with players that played on just one team
nba_player_stats <- nba_pos_stats %>% 
  filter(!(player %in% tot_players$player)) %>% 
  bind_rows(tot_players)

# Filter to only players with at least 125 minutes played
nba_filtered_stats <- nba_player_stats %>% filter(mp >= 125)

head(nba_filtered_stats)
```

## Let's work from the bottom-up...

- Review: We have $p$ variables for $n$ observations $x_1,\dots,x_n$,

- Compute the distance / dissimilarity between observations

- e.g. Euclidean distance between observations $i$ and $j$

$$d(x_i, x_j) = \sqrt{(x_{i1}-x_{j1})^2 + \cdots + (x_{ip}-x_{jp})^2}$$

What are the distances between these NBA players using `x3pa` and `trb`?

```{r nba-start-plot, eval = FALSE, echo = FALSE}
nba_filtered_stats %>%
  ggplot(aes(x = x3pa, y = trb)) + #3 point attempts per 100 possessions, total rebounds per 100 possessions
  geom_point(alpha = 0.5) + 
  theme_bw() +
  coord_fixed()
```

## Remember to standardize!

Standardization prevents variables with larger scales from dominating how clusters are defined.

```{r nba-std-plot}
nba_filtered_stats <- nba_filtered_stats %>%
  mutate(std_x3pa = as.numeric(scale(x3pa)),
         std_trb = as.numeric(scale(trb)))

nba_filtered_stats %>%
  ggplot(aes(x = std_x3pa, y = std_trb)) +
  geom_point(alpha = 0.5) + 
  theme_bw() +
  coord_fixed()
```

## Compute the distance matrix using `dist()`

- Compute pairwise Euclidean distance

```{r compute-dist}
player_dist <- dist(dplyr::select(nba_filtered_stats, #<<
                                  std_x3pa, std_trb))
```

- Returns an object of `dist` class - i.e., not a matrix

- Can convert to a matrix, then set the row and column names:

```{r dist-matrix}
player_dist_matrix <- as.matrix(player_dist) #<<
rownames(player_dist_matrix) <- nba_filtered_stats$player
colnames(player_dist_matrix) <- nba_filtered_stats$player
head(player_dist_matrix[,1:6])
```

Can convert to a long table for plotting with `ggplot`:

```{r tidy-dist-plot}
long_dist_matrix <- 
  as_tibble(player_dist_matrix) %>%
  mutate(player1 = rownames(player_dist_matrix)) %>%
  pivot_longer(cols = -player1, #<<
               names_to = "player2", #<<
               values_to = "distance") #<<

long_dist_matrix %>%
  ggplot(aes(x = player1, y = player2, 
             fill = distance)) +
  geom_tile() +
  theme_bw() +
  theme(axis.text = element_blank(), #remove axis text
        axis.ticks = element_blank(), #remove axis tick marks
        legend.position = "right") +
  scale_fill_gradient(low = "darkorange", 
                      high = "darkblue")
```

### Code interlude: arrange your heatmap with [`seriation`](https://github.com/mhahsler/seriation)

```{r seriate-plot}
library(seriation)

player_dist_seriate <- seriate(player_dist) #<<
player_order <- get_order(player_dist_seriate) #<<
player_names_order <- 
  nba_filtered_stats$player[player_order]

long_dist_matrix %>%
  mutate(player1 = 
           fct_relevel(player1, 
                       player_names_order),
         player2 = 
           fct_relevel(player2, 
                       player_names_order)) %>%
  ggplot(aes(x = player1, y = player2, 
             fill = distance)) +
  geom_tile() + theme_bw() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        legend.position = "bottom") +
  scale_fill_gradient(low = "darkorange",
                      high = "darkblue")
```

## (Agglomerative) [Hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering)

Start with all observations in their own cluster

- Step 1: Compute the pairwise dissimilarities between each cluster (e.g., distance matrix)

- Step 2: Identify the pair of clusters that are least dissimilar

- Step 3: Fuse these two clusters into a new cluster!

- Repeat Steps 1 to 3 until all observations are in the same cluster

"Bottom-up", agglomerative clustering that forms a tree / hierarchy of merging

- No mention of any randomness!

- No mention of the number of clusters $K$!

```{r}
("https://bradleyboehmke.github.io/HOML/19-hierarchical_files/figure-html/comparing-dendrogram-to-distances-1.png")
```


## How do we define dissimilarity between clusters?

We know how to compute distance / dissimilarity between two observations

But how do we handle clusters?

  - Dissimilarity between a cluster and an observation, or between two clusters
  
We need to choose a linkage function! Clusters are built up by linking them together

Compute all pairwise dissimilarities between observations in cluster 1 with observations in cluster 2

i.e. Compute the distance matrix between observations, $d(x_i, x_j)$ for $i \in C_1$ and $j \in C_2$

  - Complete linkage: Use the maximum value of these dissimilarities: $\underset{i \in C_1, j \in C_2}{\text{max}} d(x_i, x_j)$

  - Single linkage: Use the minimum value: $\underset{i \in C_1, j \in C_2}{\text{min}} d(x_i, x_j)$

  - Average linkage: Use the average value: $\frac{1}{|C_1| \cdot |C_2|} \sum_{i \in C_1} \sum_{j \in C_2} d(x_i, x_j)$
  
Define dissimilarity between two clusters based on our initial dissimilarity matrix between observations

## Complete linkage Example 

- Use the `hclust` function with a `dist()` object

- Uses `complete` linkage by default

```{r nba-complete}
nba_complete_hclust <- hclust(player_dist, method = "complete") #<<
```

- Need to use `cutree()` to return cluster labels:

```{r nba-complete-plot}
nba_filtered_stats %>%
  mutate(player_clusters = 
           as.factor(cutree(nba_complete_hclust, #<< #Returns _compact_ clusters, similar to $K$-means
                            k = 4))) %>% #<<
  ggplot(aes(x = std_x3pa, y = std_trb,
             color = player_clusters)) +
  geom_point(alpha = 0.5) + 
  ggthemes::scale_color_colorblind() +
  theme_bw() +
  theme(legend.position = "right")
```

### What are we cutting? Dendrograms

Use the [`ggdendro`](https://cran.r-project.org/web/packages/ggdendro/index.html) package (instead of `plot()`)

```{r complete-dendro}
library(ggdendro)

ggdendrogram(nba_complete_hclust, theme_dendro = F, #<<
             labels = F, leaf_labels = F) + #<< 
  labs(y = "Dissimilarity between clusters") +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid = element_blank())
```

- Each leaf is one observation

- Height of branch indicates dissimilarity between clusters

  - (After first step) Horizontal position along x-axis means nothing
  
### Cut dendrograms to obtain cluster labels

Specify the height to cut with `h` instead of `k`

```{r complete-dendro-cut}
ggdendrogram(nba_complete_hclust, theme_dendro = FALSE, #<<
             labels = FALSE, leaf_labels = FALSE) + #<< 
  labs(y = "Dissimilarity between clusters") +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid = element_blank()) +
  geom_hline(yintercept = 6, linetype = "dashed",
             color = "darkred")
```

```{r nba-h-cut}
cutree(nba_complete_hclust, h = 6) #<<
```

```{r nba-complete-cut-plot}
nba_filtered_stats %>%
  mutate(player_clusters = 
           as.factor(cutree(nba_complete_hclust, #<<
                            h = 6))) %>% #<<
  ggplot(aes(x = std_x3pa, y = std_trb,
             color = player_clusters)) +
  geom_point(alpha = 0.5) + 
  ggthemes::scale_color_colorblind() +
  theme_bw() +
  theme(legend.position = "right")
```

## Single linkage example

Change the `method` argument to `single`

Good at capturing weird shapes (e.g., ellipse). Can perform similar clustering effect as dbscan (i.e., density-based scan)

```{r single-dendro-cut}
nba_single_hclust <- 
  hclust(player_dist, method = "single")

ggdendrogram(nba_single_hclust, theme_dendro = FALSE, #<<
             labels = FALSE, leaf_labels = FALSE) + #<< 
  labs(y = "Dissimilarity between clusters") +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid = element_blank())
```

Results in a chaining effect

```{r nba-single-plot}
nba_filtered_stats %>%
  mutate(player_clusters = 
           as.factor(cutree(nba_single_hclust, #<<
                            k = 4))) %>% #<<
  ggplot(aes(x = std_x3pa, y = std_trb,
             color = player_clusters)) +
  geom_point(alpha = 0.5) + 
  ggthemes::scale_color_colorblind() +
  theme_bw() +
  theme(legend.position = "right")
```

## Average linkage example

Change the `method` argument to `average`

```{r average-dendro-cut}
nba_average_hclust <- 
  hclust(player_dist, method = "average")

ggdendrogram(nba_average_hclust, theme_dendro = FALSE, #<<
             labels = FALSE, leaf_labels = FALSE) + #<< 
  labs(y = "Dissimilarity between clusters") +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid = element_blank())
```

Closer to `complete` but varies in compactness

```{r nba-average-plot}
nba_filtered_stats %>%
  mutate(player_clusters = 
           as.factor(cutree(nba_average_hclust, #<<
                            k = 4))) %>% #<<
  ggplot(aes(x = std_x3pa, y = std_trb,
             color = player_clusters)) +
  geom_point(alpha = 0.5) + 
  ggthemes::scale_color_colorblind() +
  theme_bw() +
  theme(legend.position = "right")
```

## More linkage functions

- Centroid linkage: Computes the dissimilarity between the centroid for cluster 1 and the centroid for cluster 2

  - i.e. distance between the averages of the two clusters
  
  - use `method = centroid`

- Wardâ€™s linkage: Merges a pair of clusters to minimize the within-cluster variance

  - i.e. aim is to minimize the objection function from $K$-means
  
  - can use `ward.D` or `ward.D2` (different algorithms)

## [Minimax linkage](http://statweb.stanford.edu/~tibs/sta306bfiles/minimax-clustering.pdf)

- Each cluster is defined by a prototype observation (most representative)

- Identify the point whose farthest point is closest (hence the minimax)

- Use this minimum-maximum distance as the measure of cluster dissimilarity

- Dendogram interpretation: each point is $\leq h$ in dissimilarity to the prototype of cluster

- Cluster centers are chosen among the observations themselves - hence prototype

## Minimax linkage example

- Easily done in `R` via the [`protoclust`](https://github.com/jacobbien/protoclust) package

- Use the `protoclust()` function to apply the clustering to the `dist()` object

```{r nba-minimax}
library(protoclust)

nba_minimax <- protoclust(player_dist) #<<

#to set class and avoid dual class error: Error in if (dataClass %in% c("dendrogram", "hclust")) { :  the condition has length > 1
class(nba_minimax) = "hclust" 

ggdendrogram(nba_minimax,
             theme_dendro = FALSE, 
             labels = FALSE, 
             leaf_labels = FALSE) + 
  labs(y = "Maximum dissimilarity from prototype") +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid = element_blank())
```

## Minimax linkage example

- Want to check out the prototypes for the three clusters

- `protocut` returns the indices of the prototypes (in order of the cluster labels)

```{r}
nba_minimax <- protoclust(player_dist)

minimax_player_clusters <- 
  protocut(nba_minimax, k = 3)#<<
```

```{r prototypes-indices}
minimax_player_clusters$protos
```

- View these player rows using `slice`:

```{r proto-players}
nba_prototype = nba_filtered_stats %>%
  dplyr::select(player, pos, age, std_x3pa, std_trb) %>%
  slice(minimax_player_clusters$protos)

nba_prototype
```
- Use the `protocut()` function to make the cut 

- But then access the cluster labels `cl`

```{r nba-minimax-cut}
nba_filtered_stats %>%
  mutate(player_clusters = 
           as.factor(minimax_player_clusters$cl)) %>% #<<
  ggplot(aes(x = std_x3pa, y = std_trb,
             color = player_clusters)) +
  geom_point(alpha = 0.5) + 
  # geom_point(data = mutate(nba_prototype, player_clusters = as.factor(c(1,2,3))), #minimax reference 
  #          size = 5) +
  geom_label(data = mutate(nba_prototype, player_clusters = as.factor(c(1,2,3))), #gives name to reference point in clusters
          aes(label = player)) +
  ggthemes::scale_color_colorblind() +
  theme_bw() +
  theme(legend.position = "bottom")
```

## Wrapping up...

- For context, how does player position (`pos`) relate to our clustering results?

```{r minimax-comparison}
table("Clusters" = minimax_player_clusters$cl, "Positions" = nba_filtered_stats$pos)
```

- Can see positions tend to fall within particular clusters...

- What's the way to visually compare the two labels?

- We can easily include more variables - just changes our distance matrix

- But we might want to explore soft assignments instead...

